<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[대신증권 박세라] [AI Monthly] 멀티모달 AI 시대</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            margin: 20px;
        }
        h1 {
            font-size: 2em;
            color: #0056b3;
            margin-bottom: 20px;
        }
        h2 {
            font-size: 1.5em;
            color: #0056b3;
            margin-top: 30px;
            margin-bottom: 10px;
        }
        h3 {
            font-size: 1.2em;
            color: #0056b3;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        p {
            font-size: 1.1em;
            margin-bottom: 15px;
        }
        ul {
            margin-bottom: 15px;
        }
        li {
            font-size: 1.1em;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        .highlight {
            font-weight: bold;
            color: #007bff;
        }
        .note {
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
    <h1>[대신증권 박세라] [AI Monthly] 멀티모달 AI 시대</h1>

    <h2>I. AI 산업 트렌드</h2>
    <h3>멀티모달 AI 시대</h3>
    <p>
        AI산업은 텍스트 중심의 생성형 모델 단계를 넘어 ,텍스트 ·이미지 ·음성 ·영상 등 다양한 데이터를 동시에 이해하고 처리하는 <span class="highlight">멀티모달 AI시대로 진입</span>했다 .인간이 시각 ,청각 ,촉각 등을 결합해 인식하듯 ,AI는 여러 모달리티 (오디오 ,음성 ,영상 등)를 통합 학습함으로써 실감형 영상 생성과 종합적 지능 구현이 가능해졌다 .
    </p>

    <p>
        멀티모달 AI의 대표적인 예로 오픈 AI의 Sora 2와 구글의 Veo 3가 있다 .이들은 텍스트 입력만으로 오디오와 영상이 결합된 고품질 콘텐츠 생성이 가능 하며 , <span class="highlight">AI네이티브 콘텐츠 시대의 서막</span>을 열었다 .Sora 2와 Veo 3는 영상 제작 방식의 근본적인 변화를 불러오고 있다 .멀티모달 AI는 기존 영상 제작에서 드는 물리적비용적 제약을 넘어 텍스트 프롬프트만으로 초현실적인 숏폼 컨텐츠 생성이 가능 해졌기 때문이다 .
    </p>

    <p>
        멀티모달 AI는 유튜브 ,틱톡 ,릴스 등 주요 SNS 플랫폼에서 AI생성 영상의 확산을 촉진하며 ,향후 창작자와 소비자 모두에게 새롭고 혁신적인 제작 생태계를 조성할 것으로 기대된다 .
    </p>

    <p>
        구글의 Veo 3와 오픈 AI의 Sora 2출시는 각각 다른 방식으로 콘텐츠 제작 환경에 변화를 가져왔다 .Veo 3출시 이후 유튜브에는 AI제작 영상 채널이 등장했으며 ,이는 <span class="highlight">‘AI크리에이터 시대 ’의 본격적인 개막</span>을 의미한다 .구글은 Veo 3를 유튜브 플랫폼과 결합하고 ,AI생성물에 라벨링 및 워터마킹을 적용해 투명성과 저작권 보호를 강화할 계획이다 .
    </p>

    <p>
        오픈 AI는 Sora 2를 독립 소셜 플랫폼으로 선보였으며 ,이는 기존 숏폼 시장의 대체 가능성과 함께 크리에이터 이동성 확대 에 주목할 만하다 .Sora 2는 틱톡 스타일 인터페이스와 카메오 기능을 도입해 사용자가 얼굴 영상을 다양한 스토리에 삽입할 수 있으며 ,개인화 알고리즘을 통해 <span class="highlight">AI크리에이터 생태계 확장 전략</span>을 추진 중이다 .
    </p>

    <p>
        멀티모달 AI의 발전은 단순한 기술 혁신을 넘어 콘텐츠 산업 전반의 구조적 변화를 가속화하고 있다 .AI는 이제 단순 보조 도구를 넘어 독립적인 크리에이터이자 제작 플랫폼으로 자리매김할 전망이다 .
    </p>

    <h2>1. AI 산업 트렌드 : 멀티모달 AI 시대</h2>
    <h3>①인간처럼 소통하기 시작하는 멀티모달 AI의 등장</h3>
    <p>
        멀티모달 학습 모델은 다양한 데이터 (텍스트 , 이미지 , 비디오 등) 유형을 통합
    </p>

    <p>
        기존 AI모델은 유니모달 (Unimodal) 구조로 ,텍스트나 음성 등 하나의 데이터 양식 (Modality) 만을 중심으로 학습하고 처리함 .모달리티란 텍스트 ,음성 ,이미지 ,영상 등 서로 다른 데이터 표현 형태를 의미함
    </p>

    <p>
        과거에는 서로 다른 유형의 데이터를 처리하기 위해 각 모달리티에 특화된 개별 AI모델을 사용하고 ,그 결과를 통합해 최종 판단을 내리는 방식이었음 .반면,멀티모달 AI모델은 텍스트 ,음성 ,이미지 ,영상 등 서로 다른 형태의 데이터를 하나의 모델 내에서 동시에 이해하고 연계 처리할 수 있음
    </p>

    <p>
        최근 멀티모달 모델은 텍스트와 비전 데이터를 통합 이해하기 때문에 단순한 언어 이해를 넘어 ,시각적 인식청각적 정보까지 통합한 종합적 지능 단계로 진화 중
    </p>

    <h3>②동영상 생성형 AI(Text to Video) 와 컨텐츠 제작 방식의 변화</h3>
    <p>
        멀티모달 AI의 등장 이후 주목할 변화는 콘텐츠 제작 방식임 .멀티모달 AI인 Sora 2와 Veo 3가 올해 출시되면서 ,유튜브 숏츠 (Shorts), 틱톡 (TikTok),인스타그램 릴스 (Reels) 등 SNS 상에서 AI가 생성한 숏폼 콘텐츠가 확산되고 있음
    </p>

    <p>
        특히 현실에서 제작이 어렵거나 비용이 많이 드는 영상들이 AI를 통해 구현되면서 ,콘텐츠의 성격 자체가 변화하고 있음 .물리적으로 구현하기 까다로운 장면 ,특수효과 ,음향 -시각 결합 등은 AI를 통해 ‘텍스트 프롬프트 → 자동 생성 ’으로 가능해지면서 ,제작자와 소비자 모두에게 새로운 기회가 생김
    </p>

    <p>
        앞으로 AI를 활용한 실감형 숏폼 콘텐츠는 막대한 규모로 생산될 것으로 예상됨
    </p>

    <p>
        유튜브에는 하루 평균 약 86만 시간 (5,184 만 분)의 영상이 업로드되는 통계가 있는데 ,이중 보수적으로 5%만 생성형 AI로 제작된다고 가정할 경우 ,하루에 약 4.3만 시간 ,연간 약 1,570 만 시간의 규모의 AI생성 콘텐츠가 등장할 수 있다는 계산이 가능함
    </p>

    <h3>③구글 : Veo3, AI 크리에이터 시대의 시작</h3>
    <p>
        올해 5월,구글은 Google I/O 2025 에서 텍스트 기반의 고품질 비디오 생성 모델 Veo 3를 공개함
    </p>

    <p>
        Veo 3는 립싱크 음성 ,배경음악 ,환경음 등 오디오 요소를 통합 생성하는 기능을 지원하며 ,단순한 텍스트 프롬프트만으로도 자연스러운 영상과 사운드를 동시에 만들어냄
    </p>

    <p>
        출시 이후 Veo 3로 제작된 영상들은 유튜브 숏츠 (Shorts), 틱톡 (TikTok), 인스타그램 릴스 (Reels) 등 주요 숏폼 플랫폼에서 빠르게 확산됨 .특히 ,유리로 만든 과일을 자르는 AIASMR 영상이 바이럴 트렌드로 떠오르면서 AI생성 콘텐츠의 파급력을 입증함
    </p>

    <p>
        틱톡 플랫폼 채널 중 AI생성 ASMR 채널인 @asmraiworks 는 최고 조회수 1,260 만 회를 기록하며 주목받음
    </p>

    <p>
        향후 Veo 3는 유튜브 플랫폼에 통합될 예정이며 ,AI가 만든 영상만으로 구성된 채널들이 등장하면서 ‘AI크리에이터 시대 ’의 본격적인 개막을 보여줌
    </p>

    <h3>④오픈 AI: Sora2 소셜 iOS 애플리케이션 출시와 크리에이터의 이동</h3>
    <p>
        오픈 AI의 대표적인 동영상 생성 모델 Sora 는 2024 년 2월에 처음 공개되었으며 ,2025 년 10월 소셜 iOS 애플리케이션 Sora 2를 출시함
    </p>

    <p>
        Sora 2는 구글의 Veo 3와 마찬가지로 립싱크 음성 ,배경음악 ,환경음 등을 포함한 ‘오디오 통합 ‘기능을 지원하기 때문에 사실적인 동영상 생성이 가능함
    </p>

    <p>
        특히 Sora 2는 틱톡 (TikTok) 스타일의 인터페이스를 도입해 ,최대 10초 길이의 AI생성 숏폼 영상을 무제한으로 감상할 수 있음 .또한 ,사용자 얼굴 인증 기반의 개인화 추천 알고리즘 ,영상 리믹스 및 재생성 기능을 제공해 소셜 기능을 강화함
    </p>

    <p>
        Sora 2로 생성한 AI영상은 기존 유튜브나 틱톡 등 외부 플랫폼에서도 확산되고 있으나 ,오픈 AI가 직접 운영하는 독립적인 소셜 플랫폼 형태로 출시되면서 기존 숏폼 시장의 대체 가능성과 크리에이터 이동 가능성도 함께 주목 필요
    </p>

    <h3>⑤컨텐츠 저작권 이슈는 지속 중</h3>
    <p>
        동영상 생성 AI에는 1)학습데이터 사용 문제 ,2)생성된 영상의 저작권 침해 가능성 ,3)생성물의 소유권 및 저작권 귀속 이슈가 존재함
    </p>

    <p>
        Sora 2는 출시 직후 이용자 급증과 함께 유명 캐릭터컨텐츠 활용 영상이 빠르게 확산되자 ,권리자 수익공유 및 캐릭터 생성에 대한 세분화 제어권 도입을 밝힘 .권리자의 허용 (Opt -in)을 전제로 이용자 생성물을 합법적 수익화로 유도하는 방안
    </p>

    <p>
        Veo 3는 유튜브와의 통합을 통해 AI생성물 라벨링워터마킹 신고처리 체계를 결합해 권리 침해 및 오인 가능성을 낮추는 방향으로 운영될 것으로 예상
    </p>

    <p>
        결론적으로 Sora 2는 권리자 세분화 제어와 수익공유로 합법적 생태계를 만들려고 시도 중이며 ,Veo 3는 유튜브의 라벨링워터마킹 정책 인프라와 결합해 플랫폼 차원의 저작권 관리를 강화하는 방향 으로 진화 중
    </p>

    <h2>II. AI 기술 동향: 확산 모델</h2>
    <h3>①동영상  이미지 생성형 AI의 기초 : 확산 모델 (Diffusion Model)</h3>
    <p>이미지와 비디오 생성 형AI들은 대부분 확산 모델을 기반으로 함</p>

    <p>
        확산 모델은 무작위 노이즈 (잡음 )로 가득한 이미지에서 점진적으로 노이즈를 제거하며 데이터를 복원하는 방식으로 작동하는 딥러닝 기반 생성 모델
    </p>

    <p>
        확산 모델은 실제 이미지나 영상 데이터를 노이즈가 추가되는 방향으로 훼손 (diffusion) 시킨 뒤,학습 과정에서 그 반대 방향인 노이즈 제거 과정을 학습함 .학습이 완료된 후,모델이 완전 무작위한 노이즈로부터 시작해서 점차 실제와 유사한 고해상도 이미지나 영상을 만듦
    </p>

    <p>
        최근 확산 모델은 비디오 생성 AI인 Sora 에도 확장되었으며 ,텍스트 입력을 해석해 영상의 흐름을 조정하는 텍스트 -투-비디오 모델로 진화함 . 확산 모델은 현재 멀티모달 AI의 핵심 기반 기술로 자리잡음
    </p>

    <h3>①동영상  이미지 생성형 AI의 기초 : 확산 모델 (Diffusion Model)</h3>
    <p>
        디퓨전 모델의 작동 과정은 크게 1)순방향 확산 (Forward Diffusion) 과2)역방향 확산 (Reverse Diffusion) 으로 나뉨
    </p>

    <p>
        순방향 확산은 학습 이미지에 노이즈를 더하는 과정으로 서서히 불특정 노이즈 이미지로 변하는데 결국 추가된 노이즈로 인해 원본 이미지를 알아볼 수 없게 되는 과정
    </p>

    <p>
        반면 ,역방향 확산은 노이즈가 있는 이미지에서 노이즈를 한 단계씩 제거해서 원래 학습 이미지로 복구하는 과정
    </p>

    <p>
        역방향 확산에서 노이즈가 얼마나 추가 되었는지 알아야 원본 이미지로 복구할 수 있는데 ,이 단계에서 중요한 역할을 하는 것이 노이즈 예측기 (NoisePredictor) 임
    </p>

    <h3>②확산 모델 (Diffusion Model) 의학습 과정</h3>
    <p>
        디퓨전 모델의 학습 과정은 순방향 디퓨전을 수행하면서 노이즈 예측기를 훈련
    </p>

    <p>아래 그림 과 같은 이미지에 노이즈를 단계별로 추가</p>

    <p>그 결과를 노이즈 예측기에게 학습시키면서 훈련이 진행</p>

    <p>첫번째 학습 훈련이 마쳤을 때에는 노이즈 예측기는 이미지에 더해지는 노이즈를 예측할 수 있게 됨</p>

    <p>그 후 반대의 과정을 통해 노이즈 이미지에서 원본 이미지로 복원하는 방식을 거침</p>

    <h3>③고도화된 이미지와 영상의 효율성을 높여주는 잠재 확산 모델 (Latent Diffusion Model)</h3>
    <p>
        기존의 확산 모델은 이미지 자체에 노이즈를 추가하고 제거하기 때문에 고해상도의 이미지일 경우 많은 컴퓨팅 자원 이 필요
    </p>

    <p>
        잠재 확산 모델 은 학습 및 샘플링의 효율성을 높이기 위해 잠재 공간 (Latent Space :데이터의 특성을 나타내는 가상의 다차원 공간 )에서 원본 이미지를 압축하여 저차원 공간에서 학습 및 샘플링을 수행
    </p>

    <p>
        결국 잠재 확산 모델은 이미지에 노이즈를 추가하고 복원하는 학습 과정 (확산 모델 )을 잠재 공간 에서 수행함
    </p>

    <p>대부분의 이미지 및 동영상 AI들은 잠재 확산 모델을 사용함</p>

    <h3>④잠재 확산 모델의 이미지 및 영상 생성 과정</h3>
    <p>
        “High Resolution Image Synthesis with Latent Diffusion Model” 논문 에 따르면 잠재 공간에서 확산 (Diffusion) 과정이 진행되는데 여기에 텍스트 조건을 추가하면 텍스트 프롬프트에 맞는 이미지를 생성함
    </p>

    <p>
        잠재 확산 모델 의 이미지 생성 과정은 크게 3단계로 1)사용자가 원하는 이미지 결과 값에 대한 텍스트 프롬프트 입력 ,2)UNet 프로세스를 거쳐 ,3)VAE(Variational Auto -Encoder) 변환 작업으로 나뉨
    </p>

    <p>
        Unet 프로세스는 사용자의 텍스트 프롬프트를 받은 후 처리 과정이 잠재 공간 위에서 확산 과정이 이루어짐 .역방향 확산 과정에서 노이즈 제거 과정을 여러 번 거침.잠재공간에서 이미지의 구조적 ,시각적 정보를 유지하지만 픽셀을 최대한 압축해서 디퓨전 과정을 진행함
    </p>

    <p>
        마지막으로 VAE 변환 작업을 거치게됨 .VAE 는 위에 Latent Space 에서 가공된 데이터를 사람이 볼 수 있는 이미지인 RGB 데이터로 출력하는 변환 작업으로 ,이 과정에서 사용자가 원하는 사이즈로 이미지 크기를 조절 함
    </p>

    <h3>⑤동영상 생성형 AI의 기초 확산 트랜스포머 모델</h3>
    <p>
        동영상 생성형 AI의 선두주자인 Sora 는 확산 모델과 자연어 처리 모델인 트랜스포머 (Transformer) 모델을 결합한 구조인 확산 트랜스포머 (DiffusionTransformer) 방식을 채택함
    </p>

    <p>
        Sora 는 다양한 길이와 해상도 ,비율을 갖는 영상과 이미지를 대상으로 ,텍스트 조건부 확산 모델 (Text -Conditional Diffusion Model) 을 공동 학습함 .텍스트 조건부 확산 모델은 텍스트 입력을 받아 내용에 맞는 이미지나 영상을 생성하도록 설계된 생성형 AI임
    </p>

    <p>
        Sora 는 1)잠재 공간에서 비디오를 시공간 패치로 토큰화 ,2)토큰화된 입력을 기반으로 확산 트랜스포머가 노이즈 제거 및 영상 생성을 수행 ,3)마지막으로 디코더 (Decode) 가생성된 잠재 표현을 픽셀 수준으로 복원하는 과정을 거침
    </p>

    <p>
        Sora 는 여러 프레임간의 시간적 일관성까지 고려하도록 설계되어 있어 영상이 자연스럽고 흐름 있는 움직임을 갖출 수 있게 됨
    </p>

    <h2>III. AI 뉴스 & 데이터 대시보드</h2>

    <h3>AI 데이터 대시보드</h3>

    <h4>월간 AI 뉴스 정리</h4>

    <ul>
        <li>오픈 AI, 삼성 ·SK하이닉스와 '스타게이트 ' 메모리 공급 파트너십</li>
        <li>알트먼 , '소라 ' 저작권 침해 지적에 "수익 공유 " 제안</li>
        <li>구글 "유튜브 등 인기 앱에 제미나이 번들링은 문제 없어 "</li>
        <li>오픈 AI, ChatGPT 쇼핑에 월마트 추가 ."에이전트 커머스 지원 "</li>
        <li>MS, 포르투갈서 AI 데이터센터 용량 임대</li>
        <li>오픈 AI, AI 브라우저 ‘ChatGPT 아틀라스’ 출시</li>
        <li>앤트로픽 , 구글과 수백억달러 규모 컴퓨팅 계약 논의</li>
        <li>MS, 오픈 AI ‘스타게이트 ’ 독점 공급 해제 “현실적 판단”</li>
        <li>오픈 AI, 페이팔과 제휴 .'ChatGPT' 쇼핑에 디지털 지갑 활용</li>
        <li>이승현 인핸스 대표 “AI '커머스 실행 ' 대표 인프라 될 것”</li>
    </ul>

    <h3>AI 데이터 대시보드</h3>
    <h4>글로벌 생성형 AI 챗봇 점유율</h4>
    <p>
        글로벌 생성형 AI챗봇 중 ChatGPT 는 약 81.4%의 점유율로 압도적인 1위를 기록 중.그 뒤를 퍼플렉시티가 11.1%,마이크로소프트 (코파일럿 )가 3.5%,구글 제미나이가 3.0%로 뒤따르고 있음
    </p>
    <p>
        2025 년 9월 기준 ChatGPT 웹사이트의 월간 방문자 수는 약 58억 명으로 ,이미지 생성 기능 (지브리 스타일 업데이트 )도입 이후에도 꾸준히 증가하는 중.이에 비례해 하루 처리되는 프롬프트 수도 급격히 증가하고 있음 .2024 년 기준 하루 3,800 만 건 수준이던 처리량은 2025 년 7월 기준 25억 건을 돌파함
    </p>
    <p>
        ChatGPT 의 하루 처리되는 프롬프트 수는 1년 만에 약 65배 증가했으며 ,AI 검색이 빠르게 자리를 잡아가는 가고 있음을 보여줌
    </p>
    <p>참고로 ,구글의 하루 검색 쿼리량이 약 140 억 건인 점을 고려하면 ,ChatGPT 는 이미 구글 전체 검색 트래픽의 약 18%수준에 도달</p>

    <h3>AI 데이터 대시보드</h3>
    <h4>대형언어모델 성능 리더보드</h4>
    <p>
        Artificial Analysis 의 최신 LLM 리더보드에 따르면 ,OpenAI GPT -5가 68점으로 1위를 기록했으며 ,Grok -4XAI( 65점),Claude 3.5SonnetAnthropic( 63점),Gemini 1.5Pro Google( 60점) 등을 기록함 .
    </p>
    <p>
        이 순위는 MMLU -Pro, GPQA Diamond, Humanity’s Last Exam, LiveCodeBench ,SciCode ,AIME, MATH -500 등 7개 주요 벤치마크의 종합 평가 결과를 반영함
    </p>
    <p>
        상위권 대부분은 폐쇄형 (Closed -Source) 모델이 차지했으며 ,DeepSeek V3.1Terminus 와 Qwen 3235 BA22B2507 모델 등 일부 중국계 모델이 뒤를 잇고 있음 .이는 미국과 중국이 여전히 초거대 LLM 경쟁에서 기술 성능 지표에서 선도적임을 보여주는 결과로 평가함
    </p>

    <h3>AI 데이터 대시보드</h3>
    <h4>대형언어모델 성능 순위와 AI 모델의 속도 효율 순위</h4>
    <p>
        LMArena 의 최신 벤치마크에 따르면 ,구글의 Gemini 2.5Pro 가 1,451 점으로 전체 모델 중 가장 높은 점수를 기록함 .그 뒤로는 Anthropic 과 OpenAI 의 모델들이 상위권을 차지했으며 ,상위 10개 모델 모두 폐쇄형 (Proprietary) 모델로 ,오픈소스 모델은 포함되지 않음
    </p>
    <p>
        한편 ,출력 속도 (Output Speed) 부문에서는 OpenAI 의 GPT -OSS -120 B 모델이 초당 278 토큰 (token/sec) 으로 가장 빠른 성능을 보임 .뒤이어 Gemini 2.5Flash 가 265 token/s, Grok 4Fast 가 264 token/s 를 기록함
    </p>
    <p>
        특히 GPT -OSS -120 B는 OpenAI 가 공개한 부분 개방형 (Open -Weight) 모델로 ,단일 GPU 에서도 구동 가능한 효율적 설계를 채택함 .이 모델은 추론 ,코딩 ,에이전트 작업 수행을 위한 경량형 구조를 갖췄으며 ,연구 및 산업 응용에서도 높은 활용 가능성을 보임
    </p>

    <h3>AI 데이터 대시보드</h3>
    <h4>글로벌 AI 소프트웨어 관련 밸류체인</h4>
    <p></p>

    <h3>AI 데이터 대시보드</h3>
    <h4>글로벌 AI 소프트웨어 관련 밸류체인</h4>
    <p></p>

    <h3>AI 데이터 대시보드</h3>
    <h4>국내 상장 AI 소프트웨어 ETF 리스트</h4>
    <p></p>
</body>


<div style="margin-top: 40px; padding: 20px; border: 1px solid #ccc; border-radius: 8px; background-color: #f9f9f9; box-shadow: 0 2px 8px rgba(0,0,0,0.05); font-size: 13px; color: #666;">
    <h2 style="color: #333; font-size: 18px; margin-bottom: 12px;">Compliance Notice</h2>
    <p style="margin-bottom: 10px;">
        금융투자업규정 4-20조 1항5호사목에 따라 작성일 현재 사전고지와 관련한 사항이 없으며, 당사의 금융투자분석사는 자료작성일 현재 본 자료에
        관련하여 재산적 이해관계가 없습니다. 당사는 동 자료에 언급된 종목과 계열회사의 관계가 없으며 당사의 금융투자분석사는 본 자료의 작성과 관련하여
        외부 부당한 압력이나 간섭을 받지 않고 본인의 의견을 정확하게 반영하였습니다.
        본 자료는 투자자들의 투자판단에 참고가 되는 정보제공을 목적으로 배포되는 자료입니다. 본 자료에 수록된 내용은 당사 Research Center의 추정치로서
        오차가 발생할 수 있으며 정확성이나 완벽성은 보장하지 않습니다. 본 자료를 이용하시는 분은 동 자료와 관련한 투자의 최종 결정은 자신의 판단으로
        하시기 바랍니다.
    </p>
    <p style="font-size: 12px; color: #999; margin-top: 10px;">
        ※ 본 콘텐츠는 당사 리서치센터 보고서를 기반으로 생성된 요약·해설 자료입니다.
        본 자료는 인공지능(AI)을 활용하여 자동 생성되었으며, 투자자 이해를 돕기 위한 목적입니다.
        일부 내용은 원문과 차이가 있을 수 있으며, 최종 투자 판단은 원문 보고서를 참고하시기 바랍니다.
        본 자료는 투자 권유를 목적으로 하지 않으며, AI 생성 특성상 오류가 포함될 수 있습니다.
    </p>
</div>

</html>